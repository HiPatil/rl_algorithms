{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution |to custom environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_environment import ENVIRONMENT\n",
    "from helpers import get_q_table, improve_q_table, Parameters\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1, 6), 0, False)\n",
      "((2, 7), (-1, False))\n",
      "((1, 8), (-1, False))\n",
      "((2, 7), (-1, False))\n",
      "((1, 8), (-1, False))\n",
      "((2, 7), (-1, False))\n",
      "((3, 8), (-1, False))\n",
      "((2, 9), (-1, False))\n",
      "((3, 8), (-1, False))\n",
      "((4, 7), (-1, False))\n",
      "((5, 8), (-1, False))\n",
      "((1, 6), 0, False)\n"
     ]
    }
   ],
   "source": [
    "env = ENVIRONMENT(diagonal=True, size=10, num_enemy = 3, num_food = 1)\n",
    "q = get_q_table(size=10)\n",
    "parameters = Parameters()\n",
    "\n",
    "# Test Environment\n",
    "print(env.startover())\n",
    "\n",
    "for i in range(10):\n",
    "    print(env.step(np.random.randint(0,4)))\n",
    "    env.render()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(env.startover())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0 state: (5, 1) | Total Average Reward: -0.208 | Epsilon: 0.9\n",
      "Episode:  500 state: (1, 1) | Total Average Reward: -86.158 | Epsilon: 0.9\n",
      "Episode:  1000 state: (5, 1) | Total Average Reward: -36.484 | Epsilon: 0.9\n",
      "Episode:  1500 state: (1, 4) | Total Average Reward: -12.178 | Epsilon: 0.9\n",
      "Episode:  2000 state: (1, 4) | Total Average Reward: -8.244 | Epsilon: 0.9\n",
      "Episode:  2500 state: (3, 2) | Total Average Reward: -10.278 | Epsilon: 0.9\n",
      "Episode:  3000 state: (3, 2) | Total Average Reward: -0.498 | Epsilon: 0.9\n",
      "Episode:  3500 state: (3, 2) | Total Average Reward: 12.14 | Epsilon: 0.9\n",
      "Episode:  4000 state: (3, 2) | Total Average Reward: 8.188 | Epsilon: 0.9\n",
      "Episode:  4500 state: (1, 4) | Total Average Reward: 10.412 | Epsilon: 0.9\n",
      "Episode:  5000 state: (3, 2) | Total Average Reward: 14.888 | Epsilon: 0.9\n",
      "Episode:  5500 state: (3, 2) | Total Average Reward: 10.91 | Epsilon: 0.9\n",
      "Episode:  6000 state: (3, 2) | Total Average Reward: 10.552 | Epsilon: 0.9\n",
      "Episode:  6500 state: (1, 4) | Total Average Reward: 11.442 | Epsilon: 0.9\n",
      "Episode:  7000 state: (5, 4) | Total Average Reward: 11.726 | Epsilon: 0.9\n",
      "Episode:  7500 state: (1, 4) | Total Average Reward: 8.346 | Epsilon: 0.9\n",
      "Episode:  8000 state: (1, 4) | Total Average Reward: 11.288 | Epsilon: 0.9\n",
      "Episode:  8500 state: (1, 4) | Total Average Reward: 7.482 | Epsilon: 0.9\n",
      "Episode:  9000 state: (3, 2) | Total Average Reward: 11.604 | Epsilon: 0.9\n",
      "Episode:  9500 state: (1, 4) | Total Average Reward: 11.85 | Epsilon: 0.9\n",
      "Episode:  10000 state: (3, 2) | Total Average Reward: 9.398 | Epsilon: 0.9\n",
      "Episode:  10500 state: (1, 4) | Total Average Reward: 8.49 | Epsilon: 0.9\n",
      "Episode:  11000 state: (3, 2) | Total Average Reward: 10.184 | Epsilon: 0.9\n",
      "Episode:  11500 state: (3, 2) | Total Average Reward: 14.138 | Epsilon: 0.9\n",
      "Episode:  12000 state: (1, 4) | Total Average Reward: 8.842 | Epsilon: 0.9\n",
      "Episode:  12500 state: (3, 2) | Total Average Reward: 12.814 | Epsilon: 0.9\n",
      "Episode:  13000 state: (3, 2) | Total Average Reward: 11.07 | Epsilon: 0.9\n",
      "Episode:  13500 state: (1, 4) | Total Average Reward: 12.504 | Epsilon: 0.9\n",
      "Episode:  14000 state: (1, 4) | Total Average Reward: 11.502 | Epsilon: 0.9\n",
      "Episode:  14500 state: (1, 4) | Total Average Reward: 12.902 | Epsilon: 0.9\n",
      "Episode:  15000 state: (1, 4) | Total Average Reward: 12.012 | Epsilon: 0.9\n",
      "Episode:  15500 state: (1, 4) | Total Average Reward: 11.502 | Epsilon: 0.9\n",
      "Episode:  16000 state: (3, 2) | Total Average Reward: 11.676 | Epsilon: 0.9\n",
      "Episode:  16500 state: (3, 2) | Total Average Reward: 11.482 | Epsilon: 0.9\n",
      "Episode:  17000 state: (1, 4) | Total Average Reward: 11.89 | Epsilon: 0.9\n",
      "Episode:  17500 state: (1, 4) | Total Average Reward: 5.19 | Epsilon: 0.9\n",
      "Episode:  18000 state: (3, 2) | Total Average Reward: 16.164 | Epsilon: 0.9\n",
      "Episode:  18500 state: (1, 4) | Total Average Reward: 11.4 | Epsilon: 0.9\n",
      "Episode:  19000 state: (3, 2) | Total Average Reward: 8.596 | Epsilon: 0.9\n",
      "Episode:  19500 state: (5, 1) | Total Average Reward: 10.08 | Epsilon: 0.9\n",
      "Episode:  20000 state: (1, 4) | Total Average Reward: 11.138 | Epsilon: 0.9\n",
      "Episode:  20500 state: (3, 2) | Total Average Reward: 14.016 | Epsilon: 0.9\n",
      "Episode:  21000 state: (1, 4) | Total Average Reward: 5.428 | Epsilon: 0.9\n",
      "Episode:  21500 state: (3, 2) | Total Average Reward: 10.352 | Epsilon: 0.9\n",
      "Episode:  22000 state: (3, 2) | Total Average Reward: 10.742 | Epsilon: 0.9\n",
      "Episode:  22500 state: (3, 2) | Total Average Reward: 11.208 | Epsilon: 0.9\n",
      "Episode:  23000 state: (1, 4) | Total Average Reward: 8.676 | Epsilon: 0.9\n",
      "Episode:  23500 state: (3, 2) | Total Average Reward: 9.416 | Epsilon: 0.9\n",
      "Episode:  24000 state: (3, 2) | Total Average Reward: 9.276 | Epsilon: 0.9\n",
      "Episode:  24500 state: (3, 2) | Total Average Reward: 17.774 | Epsilon: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Improve the Q-value table\n",
    "q = improve_q_table(env, q, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the q table\n",
    "import time\n",
    "with open(f\"qtable-{int(time.time())}.pickle\", \"wb\") as f:\n",
    "    pickle.dump(q, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.HM_EPISODES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
