{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution ne, you can use nbconvert:to custom environment\n",
    "# Solved using Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_environment import ENVIRONMENT\n",
    "from helpers import get_q_table, improve_q_table, Parameters\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ENVIRONMENT(diagonal=True, size=10, num_enemy = 3, num_food = 1)\n",
    "q = get_q_table(size=10)\n",
    "parameters = Parameters()\n",
    "\n",
    "# # Test Environment\n",
    "# for i in range(10):\n",
    "#     print(env.step(np.random.randint(0,4)))\n",
    "#     env.render()\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "# print(env.startover())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0 state: (8, 7) | Total Average Reward: 0.19 | Epsilon: 0.9\n",
      "Episode:  500 state: (8, 7) | Total Average Reward: 21.722 | Epsilon: 0.9\n",
      "Episode:  1000 state: (8, 7) | Total Average Reward: 25.412 | Epsilon: 0.9\n",
      "Episode:  1500 state: (8, 7) | Total Average Reward: 25.596 | Epsilon: 0.9\n",
      "Episode:  2000 state: (8, 7) | Total Average Reward: 24.402 | Epsilon: 0.9\n",
      "Episode:  2500 state: (6, 9) | Total Average Reward: 24.218 | Epsilon: 0.9\n",
      "Episode:  3000 state: (8, 7) | Total Average Reward: 26.726 | Epsilon: 0.9\n",
      "Episode:  3500 state: (8, 7) | Total Average Reward: 24.448 | Epsilon: 0.9\n",
      "Episode:  4000 state: (8, 7) | Total Average Reward: 27.818 | Epsilon: 0.9\n",
      "Episode:  4500 state: (8, 7) | Total Average Reward: 24.584 | Epsilon: 0.9\n",
      "Episode:  5000 state: (6, 9) | Total Average Reward: 22.97 | Epsilon: 0.9\n",
      "Episode:  5500 state: (8, 7) | Total Average Reward: 24.222 | Epsilon: 0.9\n",
      "Episode:  6000 state: (6, 9) | Total Average Reward: 23.96 | Epsilon: 0.9\n",
      "Episode:  6500 state: (8, 7) | Total Average Reward: 24.91 | Epsilon: 0.9\n",
      "Episode:  7000 state: (6, 8) | Total Average Reward: 23.242 | Epsilon: 0.9\n",
      "Episode:  7500 state: (8, 7) | Total Average Reward: 24.04 | Epsilon: 0.9\n",
      "Episode:  8000 state: (6, 9) | Total Average Reward: 23.782 | Epsilon: 0.9\n",
      "Episode:  8500 state: (8, 7) | Total Average Reward: 23.458 | Epsilon: 0.9\n",
      "Episode:  9000 state: (6, 8) | Total Average Reward: 23.446 | Epsilon: 0.9\n",
      "Episode:  9500 state: (6, 8) | Total Average Reward: 24.014 | Epsilon: 0.9\n",
      "Episode:  10000 state: (8, 7) | Total Average Reward: 23.22 | Epsilon: 0.9\n",
      "Episode:  10500 state: (6, 9) | Total Average Reward: 22.506 | Epsilon: 0.9\n",
      "Episode:  11000 state: (8, 7) | Total Average Reward: 27.194 | Epsilon: 0.9\n",
      "Episode:  11500 state: (6, 9) | Total Average Reward: 25.334 | Epsilon: 0.9\n",
      "Episode:  12000 state: (8, 7) | Total Average Reward: 26.202 | Epsilon: 0.9\n",
      "Episode:  12500 state: (8, 7) | Total Average Reward: 24.35 | Epsilon: 0.9\n",
      "Episode:  13000 state: (8, 7) | Total Average Reward: 24.902 | Epsilon: 0.9\n",
      "Episode:  13500 state: (8, 7) | Total Average Reward: 23.574 | Epsilon: 0.9\n",
      "Episode:  14000 state: (8, 7) | Total Average Reward: 22.754 | Epsilon: 0.9\n",
      "Episode:  14500 state: (8, 7) | Total Average Reward: 24.758 | Epsilon: 0.9\n",
      "Episode:  15000 state: (8, 7) | Total Average Reward: 23.026 | Epsilon: 0.9\n",
      "Episode:  15500 state: (6, 9) | Total Average Reward: 22.656 | Epsilon: 0.9\n",
      "Episode:  16000 state: (6, 9) | Total Average Reward: 25.308 | Epsilon: 0.9\n",
      "Episode:  16500 state: (6, 8) | Total Average Reward: 23.498 | Epsilon: 0.9\n",
      "Episode:  17000 state: (6, 9) | Total Average Reward: 24.134 | Epsilon: 0.9\n",
      "Episode:  17500 state: (8, 7) | Total Average Reward: 27.852 | Epsilon: 0.9\n",
      "Episode:  18000 state: (8, 7) | Total Average Reward: 25.852 | Epsilon: 0.9\n",
      "Episode:  18500 state: (6, 9) | Total Average Reward: 25.556 | Epsilon: 0.9\n",
      "Episode:  19000 state: (8, 7) | Total Average Reward: 25.786 | Epsilon: 0.9\n",
      "Episode:  19500 state: (8, 7) | Total Average Reward: 23.492 | Epsilon: 0.9\n",
      "Episode:  20000 state: (6, 9) | Total Average Reward: 24.356 | Epsilon: 0.9\n",
      "Episode:  20500 state: (8, 7) | Total Average Reward: 27.202 | Epsilon: 0.9\n",
      "Episode:  21000 state: (8, 7) | Total Average Reward: 25.628 | Epsilon: 0.9\n",
      "Episode:  21500 state: (8, 7) | Total Average Reward: 23.318 | Epsilon: 0.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8cfd7790e9bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Improve the Q-value table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimprove_q_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/working_algorithms/custom_env/helpers.py\u001b[0m in \u001b[0;36mimprove_q_table\u001b[0;34m(env, q, parameters, verbose)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/working_algorithms/custom_env/custom_environment.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, renderTime)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;31m# cv2.destroyAllWindows()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Improve the Q-value table\n",
    "q = improve_q_table(env, q, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
